{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification prediction for popularity of a song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, softmax\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spotify_data/spotify_songs.csv\")\n",
    "\n",
    "df = df.drop(['track_id','track_name','track_album_id','track_album_name','playlist_id','playlist_name'], axis= 1 ) # These features are not needed for prediction\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of track_popularity\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df['track_popularity'], bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Popularity')\n",
    "plt.xlabel('Track popularity')\n",
    "plt.ylabel('Amount')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null or NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_popularity = df['track_popularity'].isnull().any()\n",
    "\n",
    "missing_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the songs with popularity zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['track_popularity'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of track_popularity\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df['track_popularity'], bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Popularity')\n",
    "plt.xlabel('Track popularity')\n",
    "plt.ylabel('Amount')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide track_popularity in classes(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges and labels\n",
    "bin_edges = [0, 25, 40, 55, 70, 100]\n",
    "bin_labels = [0, 1, 2, 3, 4]# ['Trash', 'Flop', 'Average', 'Hit', 'Monsterhit']\n",
    "\n",
    "# Create a new column 'popularity_label' based on the bins\n",
    "df['track_popularity'] = pd.cut(df['track_popularity'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "df['track_popularity_label'] = df['track_popularity'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['track_popularity'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change release date to release year + scale duration to seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make df['release_year'] a new column that stores the first 4 characters of df['track_album_release_date'] which is of Object type df['release_year'] = df['track_album_release_date'].astype(str).str[0:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release date to years\n",
    "df['track_album_release_date'] = pd.to_datetime(df['track_album_release_date'], errors='coerce')\n",
    "df['release_year'] = (df['track_album_release_date'].dt.year)\n",
    "\n",
    "df = df.drop(['track_album_release_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track duration from ms to s\n",
    "df['duration_ms'] = df['duration_ms']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'duration_ms': 'duration_s'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(['track_popularity_label', 'track_artist', 'playlist_genre', 'playlist_subgenre'],axis=1).to_numpy(), df['track_popularity_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of y is: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED CELL: Sequential model\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        tf.keras.Input(shape=(13,)),    #specify input shape\n",
    "        Dense(200, activation=relu, name=\"L1\"),\n",
    "        Dense(100, activation=relu, name=\"L2\"),\n",
    "        Dense(20, activation=linear, name=\"L3\"),\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    ], name = \"my_model\"\n",
    ")\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X,y,\n",
    "    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_tf(history):\n",
    "    fig,ax = plt.subplots(1,1, figsize = (5,5))\n",
    "    ax.plot(history.history['loss'], label='loss')\n",
    "    ax.set_ylim([0, 10])\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('loss (cost)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_tf(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "#give df value at row 23\n",
    "df.iloc[2]\n",
    "#give me the row with the highest track_popularity_label         \n",
    "df.loc[df['track_popularity_label'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ed_IHE_Remix = X[41]\n",
    "print(Ed_IHE_Remix.shape)\n",
    "prediction = model.predict(Ed_IHE_Remix.reshape(1,13))\n",
    "print(f\" predicting a Two: \\n{prediction}\")  # Moet toch zijn: predicting a Four?\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\") # Moet toch zijn: predicting a Four?\n",
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "print(f\"np.argmax(prediction_p): {yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(5,5))\n",
    "fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.91]) #[left, bottom, right, top]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "\n",
    "    # Predict using the Neural Network\n",
    "    prediction = model.predict(X[random_index].reshape(1,13))\n",
    "    prediction_p = tf.nn.softmax(prediction)\n",
    "    yhat = np.argmax(prediction_p)\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y[random_index]},{yhat}\",fontsize=10)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "fig.suptitle(\"Label, yhat\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_errors(model,X,y):\n",
    "    f = model.predict(X)\n",
    "    yhat = np.argmax(f, axis=1)\n",
    "    doo = yhat != y[:]\n",
    "    idxs = np.where(yhat != y[:])[0]\n",
    "    if len(idxs) == 0:\n",
    "        print(\"no errors found\")\n",
    "    else:\n",
    "        cnt = min(8, len(idxs))\n",
    "        fig, ax = plt.subplots(1,cnt, figsize=(5,1.2))\n",
    "        fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.80]) #[left, bottom, right, top]\n",
    "\n",
    "        for i in range(cnt):\n",
    "            j = idxs[i]\n",
    "            \n",
    "            # Predict using the Neural Network\n",
    "            prediction = model.predict(X[j].reshape(1,13))\n",
    "            prediction_p = tf.nn.softmax(prediction)\n",
    "            yhat = np.argmax(prediction_p)\n",
    "\n",
    "            # Display the label above the image\n",
    "            ax[i].set_title(f\"{y[j]},{yhat}\",fontsize=10)\n",
    "            ax[i].set_axis_off()\n",
    "            fig.suptitle(\"Label, yhat\", fontsize=12)\n",
    "    return(len(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"{display_errors(model,X,y)} errors out of {len(X)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
